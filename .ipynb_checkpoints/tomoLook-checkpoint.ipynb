{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Look at Tomography Shots "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Data Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import hvplot.pandas\n",
    "import numpy as np\n",
    "import matplotlib.dates as dates\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import holoviews as hv\n",
    "from holoviews import dim, opts\n",
    "import hvplot.dask\n",
    "import dask.dataframe as dd\n",
    "hv.extension('bokeh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "def dateparse (date_string):\n",
    "    return datetime.datetime.strptime(date_string, '%d-%m-%Y %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head ~/Dropbox/QueensCollege/Research/BransfieldStrait/data/seismic/tomography/TimeTAG/T_01.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -40 ~/Dropbox/QueensCollege/Research/BransfieldStrait/data/seismic/tomography/P1/T_01.1.190"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grav_file1 = '~/Dropbox/QueensCollege/Research/BransfieldStrait/data/grav/proc/20012019.gravimetro_bruto.proc'\n",
    "grav_file2 = '~/Dropbox/QueensCollege/Research/BransfieldStrait/data/grav/proc/21012019.gravimetro_bruto.proc'\n",
    "grav_file3 = '~/Dropbox/QueensCollege/Research/BransfieldStrait/data/grav/proc/22012019.gravimetro_bruto.proc'\n",
    "grav_file4 = '~/Dropbox/QueensCollege/Research/BransfieldStrait/data/grav/proc/23012019.gravimetro_bruto.proc'\n",
    "grav_file5 = '~/Dropbox/QueensCollege/Research/BransfieldStrait/data/grav/proc/24012019.gravimetro_bruto.proc'\n",
    "grav_file6 = '~/Dropbox/QueensCollege/Research/BransfieldStrait/data/grav/proc/25012019.gravimetro_bruto.proc'\n",
    "grav_file7 = '~/Dropbox/QueensCollege/Research/BransfieldStrait/data/grav/proc/26012019.gravimetro_bruto.proc'\n",
    "grav_file8 = '~/Dropbox/QueensCollege/Research/BransfieldStrait/data/grav/proc/27012019.gravimetro_bruto.proc'\n",
    "grav_file9 = '~/Dropbox/QueensCollege/Research/BransfieldStrait/data/grav/proc/28012019.gravimetro_bruto.proc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grav = pd.read_csv(grav_file1, parse_dates=True, date_parser=dateparse, index_col='fecha',\n",
    "                       dtype = {'Date': object,'status': np.float64,\n",
    "                                'gravimetria_bruta': np.float64, 'spring_tension': np.float64,\n",
    "                                'longitud': np.float64, 'latitud': np.float64,\n",
    "                                'velocidad': np.float64,'rumbo': np.float64 })\n",
    "\n",
    "df_grav = df_grav.append(pd.read_csv(grav_file2, parse_dates=True, date_parser=dateparse, index_col='fecha',\n",
    "                       dtype = {'Date': object,'status': np.float64,\n",
    "                                'gravimetria_bruta': np.float64, 'spring_tension': np.float64,\n",
    "                                'longitud': np.float64, 'latitud': np.float64,\n",
    "                                'velocidad': np.float64,'rumbo': np.float64}))\n",
    "\n",
    "df_grav = df_grav.append(pd.read_csv(grav_file3, parse_dates=True, date_parser=dateparse, index_col='fecha',\n",
    "                       dtype = {'Date': object,'status': np.float64,\n",
    "                                'gravimetria_bruta': np.float64, 'spring_tension': np.float64,\n",
    "                                'longitud': np.float64, 'latitud': np.float64,\n",
    "                                'velocidad': np.float64,'rumbo': np.float64}))\n",
    "\n",
    "df_grav = df_grav.append(pd.read_csv(grav_file4, parse_dates=True, date_parser=dateparse, index_col='fecha',\n",
    "                       dtype = {'Date': object,'status': np.float64,\n",
    "                                'gravimetria_bruta': np.float64, 'spring_tension': np.float64,\n",
    "                                'longitud': np.float64, 'latitud': np.float64,\n",
    "                                'velocidad': np.float64,'rumbo': np.float64}))\n",
    "\n",
    "df_grav = df_grav.append(pd.read_csv(grav_file5, parse_dates=True, date_parser=dateparse, index_col='fecha',\n",
    "                       dtype = {'Date': object,'status': np.float64,\n",
    "                                'gravimetria_bruta': np.float64, 'spring_tension': np.float64,\n",
    "                                'longitud': np.float64, 'latitud': np.float64,\n",
    "                                'velocidad': np.float64,'rumbo': np.float64}))\n",
    "\n",
    "df_grav = df_grav.append(pd.read_csv(grav_file6, parse_dates=True, date_parser=dateparse, index_col='fecha',\n",
    "                       dtype = {'Date': object,'status': np.float64,\n",
    "                                'gravimetria_bruta': np.float64, 'spring_tension': np.float64,\n",
    "                                'longitud': np.float64, 'latitud': np.float64,\n",
    "                                'velocidad': np.float64,'rumbo': np.float64}))\n",
    "\n",
    "df_grav = df_grav.append(pd.read_csv(grav_file7, parse_dates=True, date_parser=dateparse, index_col='fecha',\n",
    "                       dtype = {'Date': object,'status': np.float64,\n",
    "                                'gravimetria_bruta': np.float64, 'spring_tension': np.float64,\n",
    "                                'longitud': np.float64, 'latitud': np.float64,\n",
    "                                'velocidad': np.float64,'rumbo': np.float64}))\n",
    "\n",
    "df_grav = df_grav.append(pd.read_csv(grav_file8, parse_dates=True, date_parser=dateparse, index_col='fecha',\n",
    "                       dtype = {'Date': object,'status': np.float64,\n",
    "                                'gravimetria_bruta': np.float64, 'spring_tension': np.float64,\n",
    "                                'longitud': np.float64, 'latitud': np.float64,\n",
    "                                'velocidad': np.float64,'rumbo': np.float64}))\n",
    "\n",
    "df_grav = df_grav.append(pd.read_csv(grav_file9, parse_dates=True, date_parser=dateparse, index_col='fecha',\n",
    "                       dtype = {'Date': object,'status': np.float64,\n",
    "                                'gravimetria_bruta': np.float64, 'spring_tension': np.float64,\n",
    "                                'longitud': np.float64, 'latitud': np.float64,\n",
    "                                'velocidad': np.float64,'rumbo': np.float64}))\n",
    "\n",
    "\n",
    "df_grav.index = pd.to_datetime(df_grav.index.values)\n",
    "df_grav['fecha_telegrama'] = pd.to_datetime(df_grav['fecha_telegrama'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_grav.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Bathy Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bathy_file1 = '~/Dropbox/QueensCollege/Research/BransfieldStrait/data/position/20012019.posicion.proc'\n",
    "bathy_file2 = '~/Dropbox/QueensCollege/Research/BransfieldStrait/data/position/21012019.posicion.proc'\n",
    "bathy_file3 = '~/Dropbox/QueensCollege/Research/BransfieldStrait/data/position/22012019.posicion.proc'\n",
    "bathy_file4 = '~/Dropbox/QueensCollege/Research/BransfieldStrait/data/position/23012019.posicion.proc'\n",
    "bathy_file5 = '~/Dropbox/QueensCollege/Research/BransfieldStrait/data/position/24012019.posicion.proc'\n",
    "bathy_file6 = '~/Dropbox/QueensCollege/Research/BransfieldStrait/data/position/25012019.posicion.proc'\n",
    "bathy_file7 = '~/Dropbox/QueensCollege/Research/BransfieldStrait/data/position/26012019.posicion.proc'\n",
    "bathy_file8 = '~/Dropbox/QueensCollege/Research/BransfieldStrait/data/position/27012019.posicion.proc'\n",
    "bathy_file9 = '~/Dropbox/QueensCollege/Research/BransfieldStrait/data/position/28012019.posicion.proc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!head ~/Dropbox/QueensCollege/Research/BransfieldStrait/data/position/21012019.posicion.proc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bath = pd.read_csv(bathy_file1, parse_dates=True, date_parser=dateparse, index_col='fecha',\n",
    "                       dtype = {'Date': object,'longitud': np.float64,\n",
    "                                'latitud': np.float64, 'rumbo': np.float64,\n",
    "                                'velocidad': np.float64, 'profundidad': np.float64,\n",
    "                                'cog': np.float64,'sog': np.float64 })\n",
    "\n",
    "df_bath = df_bath.append(pd.read_csv(bathy_file2, parse_dates=True, date_parser=dateparse, index_col='fecha',\n",
    "                       dtype = {'Date': object,'longitud': np.float64,\n",
    "                                'latitud': np.float64, 'rumbo': np.float64,\n",
    "                                'velocidad': np.float64, 'profundidad': np.float64,\n",
    "                                'cog': np.float64,'sog': np.float64 }))\n",
    "\n",
    "df_bath = df_bath.append(pd.read_csv(bathy_file3, parse_dates=True, date_parser=dateparse, index_col='fecha',\n",
    "                       dtype = {'Date': object,'longitud': np.float64,\n",
    "                                'latitud': np.float64, 'rumbo': np.float64,\n",
    "                                'velocidad': np.float64, 'profundidad': np.float64,\n",
    "                                'cog': np.float64,'sog': np.float64 }))\n",
    "\n",
    "df_bath = df_bath.append(pd.read_csv(bathy_file4, parse_dates=True, date_parser=dateparse, index_col='fecha',\n",
    "                       dtype = {'Date': object,'longitud': np.float64,\n",
    "                                'latitud': np.float64, 'rumbo': np.float64,\n",
    "                                'velocidad': np.float64, 'profundidad': np.float64,\n",
    "                                'cog': np.float64,'sog': np.float64 }))\n",
    "\n",
    "df_bath = df_bath.append(pd.read_csv(bathy_file5, parse_dates=True, date_parser=dateparse, index_col='fecha',\n",
    "                       dtype = {'Date': object,'longitud': np.float64,\n",
    "                                'latitud': np.float64, 'rumbo': np.float64,\n",
    "                                'velocidad': np.float64, 'profundidad': np.float64,\n",
    "                                'cog': np.float64,'sog': np.float64 }))\n",
    "\n",
    "df_bath = df_bath.append(pd.read_csv(bathy_file6, parse_dates=True, date_parser=dateparse, index_col='fecha',\n",
    "                       dtype = {'Date': object,'longitud': np.float64,\n",
    "                                'latitud': np.float64, 'rumbo': np.float64,\n",
    "                                'velocidad': np.float64, 'profundidad': np.float64,\n",
    "                                'cog': np.float64,'sog': np.float64 }))\n",
    "\n",
    "df_bath = df_bath.append(pd.read_csv(bathy_file7, parse_dates=True, date_parser=dateparse, index_col='fecha',\n",
    "                       dtype = {'Date': object,'longitud': np.float64,\n",
    "                                'latitud': np.float64, 'rumbo': np.float64,\n",
    "                                'velocidad': np.float64, 'profundidad': np.float64,\n",
    "                                'cog': np.float64,'sog': np.float64 }))\n",
    "\n",
    "df_bath = df_bath.append(pd.read_csv(bathy_file8, parse_dates=True, date_parser=dateparse, index_col='fecha',\n",
    "                       dtype = {'Date': object,'longitud': np.float64,\n",
    "                                'latitud': np.float64, 'rumbo': np.float64,\n",
    "                                'velocidad': np.float64, 'profundidad': np.float64,\n",
    "                                'cog': np.float64,'sog': np.float64 }))\n",
    "\n",
    "df_bath = df_bath.append(pd.read_csv(bathy_file9, parse_dates=True, date_parser=dateparse, index_col='fecha',\n",
    "                       dtype = {'Date': object,'longitud': np.float64,\n",
    "                                'latitud': np.float64, 'rumbo': np.float64,\n",
    "                                'velocidad': np.float64, 'profundidad': np.float64,\n",
    "                                'cog': np.float64,'sog': np.float64 }))\n",
    "\n",
    "df_bath.index = pd.to_datetime(df_bath.index.values)\n",
    "df_bath['fecha_telegrama'] = pd.to_datetime(df_bath['fecha_telegrama'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_bath.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.merge(df_bath, df_grav,how='inner', indicator=True, left_index=True, right_index=True, suffixes=('_B', '_G'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gravMerge = test[test['_merge'] == 'both']\n",
    "del df_gravMerge['_merge']\n",
    "df_gravMerge['longitud'] = (df_gravMerge['longitud_B'] + df_gravMerge['longitud_G'])/2\n",
    "df_gravMerge['latitud'] = (df_gravMerge['latitud_B'] + df_gravMerge['latitud_G'])/2\n",
    "df_gravMerge['rumbo'] = (df_gravMerge['rumbo_B'] + df_gravMerge['rumbo_G'])/2\n",
    "df_gravMerge['velocidad'] = (df_gravMerge['velocidad_B'] + df_gravMerge['velocidad_G'])/2\n",
    "del df_gravMerge['longitud_B']\n",
    "del df_gravMerge['latitud_B']\n",
    "del df_gravMerge['rumbo_B']\n",
    "del df_gravMerge['velocidad_B']\n",
    "del df_gravMerge['fecha_telegrama_B']\n",
    "del df_gravMerge['longitud_G']\n",
    "del df_gravMerge['latitud_G']\n",
    "del df_gravMerge['rumbo_G']\n",
    "del df_gravMerge['velocidad_G']\n",
    "del df_gravMerge['fecha_telegrama_G']\n",
    "del df_gravMerge['status']\n",
    "df_gravMerge.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eötvös correction\n",
    "### δgEötvös =4.040 v sinα cosλ + 0.001211v2 mGal\n",
    "#### v = speed in km/hr\n",
    "#### λ = latitude\n",
    "#### α = direction of travel (azimuth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gravMerge['eotvos'] = 4.040 * df_gravMerge['sog'].values * df_gravMerge['cog'].apply(np.sin)* df_gravMerge['latitud'].apply(np.cos) + (0.001211 * df_gravMerge['sog']**2 )\n",
    "df_gravMerge.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latitude Correction \n",
    "https://rallen.berkeley.edu/teaching/F04_GEO594_IntroAppGeophys/Lectures/L03_GravCorrAnalysis.pdf\n",
    "#### Geodetic Reference System (GRS-1967) formula\n",
    "#### gφ =9.780318(1+0.0053024sin2φ−0.0000059sin2 2φ) m/s2\n",
    "\n",
    "## Bouguer correction\n",
    "#### Accounts for rock thickness between current and base station elevation\n",
    "#### Treat the rock as an infinite horizontal slab:\n",
    "#### CB = 0.000419∆hρ where ∆h is in m and ρ is in km/m3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gravMerge.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downsample the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_minuteGrav = pd.DataFrame()\n",
    "df_minuteGrav['proc_gravity'] = df_gravMerge.gravimetria_bruta.resample('min').mean()\n",
    "df_minuteGrav['eotvos'] = df_gravMerge.eotvos.resample('min').mean()\n",
    "df_minuteGrav['grav_corr'] = df_gravMerge.gravimetria_bruta.resample('min').mean() - df_gravMerge.eotvos.resample('min').mean()\n",
    "df_minuteGrav['lon'] = df_gravMerge.longitud.resample('min').mean()\n",
    "df_minuteGrav['lat'] = df_gravMerge.latitud.resample('min').mean()\n",
    "df_minuteGrav['speed'] = df_gravMerge.velocidad.resample('min').mean()\n",
    "df_minuteGrav['heading'] = df_gravMerge.rumbo.resample('min').mean()\n",
    "df_minuteGrav['depth'] = df_gravMerge.profundidad.resample('min').mean()\n",
    "df_minuteGrav.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_minuteGrav2=df_minuteGrav.loc['2019-01-20 00:00:00':'2019-01-24 00:00:00']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_minuteGrav3=df_minuteGrav.loc['2019-01-26 21:00:00':'2019-01-27 06:00:00']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_minuteGrav3.hvplot.points('lon', 'lat', \n",
    "                      height=500, \n",
    "                      color='proc_gravity', \n",
    "                      cmap='colorwheel', \n",
    "                      size=2, \n",
    "                      hover_cols=['depth'], bgcolor='grey').opts(bgcolor='grey')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Things to notice:\n",
    "1. The depth signiature is visable\n",
    "2. Examine crossing paths... there is a directioal dependence to our readings related to ship direction. \n",
    "3. Is the difference between these lines just the ETVOS correction or are their other corrections that need to be applied? \n",
    "4. Whould you please share the processing stream? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_minuteGrav3.hvplot.points('index', 'grav_corr', color='proc_gravity',\n",
    "                             cmap='colorwheel', size=.5,\n",
    "                             hover_cols=['heading']).opts(bgcolor='grey')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_minuteGrav3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The gravitational constant in SI units :math:`m^3 kg^{-1} s^{-1}`\n",
    "## GRAVITATIONAL_CONST = 0.00000000006673"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bouguer Correction\n",
    "#### The mass of the material between the gravity station and the datum also causes a variation of gravity with elevation (Figure 1). This mass effect causes gravity at higher stations to be greater than at stations with lower elevations and thus partly offsets the Free Air effect. To calculate the effect of this mass, a model of the topography must be constructed and its density must be estimated.\n",
    "\n",
    "#### The traditional approach is crude but has been proven to be effective. In this approach, each station is assumed to sit on a slab of material that extends to infinity laterally and to the elevation datum vertically (Figure 1). The formula for the gravitational attraction of this infinite slab is derived by employing a volume integral to calculate its mass. The resulting correction is named for the French geodesist Pierre Bouguer:\n",
    "\n",
    "## Bouguer Correction = BC = 2pgrh, where g is the International gravitational constant, r is the density, and h = (elevation - datum elevation).\n",
    "\n",
    "#### As discussed below, the need to estimate density for the calculation of the Bouguer correction is a significant source of uncertainty in gravity studies. With Gobs being observed gravity corrected for drift and tides, the Bouguer anomaly (BA) is then defined as:\n",
    "\n",
    "## BA = Gobs - Gt + FAC - BC\n",
    "\n",
    "#### If terrain corrections (see below) are not applied, the term simple Bouguer anomaly is used. If they have, the term complete Bouguer anomaly is used. A second order correction to account for the curvature of the Earth is often added to this calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ellipsoid = get_ellipsoid()\n",
    " #Convert latitude to radians\n",
    "    latitude_rad = np.radians(latitude)\n",
    "     prime_vertical_radius = ellipsoid.semimajor_axis / np.sqrt(1 - ellipsoid.first_eccentricity ** 2 * np.sin(latitude_rad) ** 2)\n",
    "        # Instead of computing X and Y, we only comupute the projection on the XY plane:\n",
    "        # xy_projection = sqrt( X**2 + Y**2 )\n",
    " xy_projection = (height + prime_vertical_radius) * np.cos(latitude_rad)\n",
    " z_cartesian = (height + (1 - ellipsoid.first_eccentricity ** 2) * prime_vertical_radius) * np.sin(latitude_rad)\n",
    " radius = np.sqrt(xy_projection ** 2 + z_cartesian ** 2)\n",
    " geocentric_latitude = 180 / np.pi * np.arcsin(z_cartesian / radius)\n",
    "\n",
    "    return geocentric_latitude, radius\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
