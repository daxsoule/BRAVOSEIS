{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Look at Gravity Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Data Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import hvplot.pandas\n",
    "import numpy as np\n",
    "import matplotlib.dates as dates\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import holoviews as hv\n",
    "from holoviews import dim, opts\n",
    "import hvplot.dask\n",
    "hv.extension('bokeh')\n",
    "import glob, os\n",
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "\n",
    "def inc(x):\n",
    "    sleep(1)\n",
    "    return x + 1\n",
    "\n",
    "def add(x, y):\n",
    "    sleep(1)\n",
    "    return x + y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start a Dask Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client, LocalCluster\n",
    "cluster = LocalCluster()\n",
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "def dateparse (date_string):\n",
    "    return datetime.datetime.strptime(date_string, '%d-%m-%Y %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!ls /home/jovyan/data/bravoseis_data/SADO/jan_2019/gravimetro_bruto.proc/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head /Users/dsoule/data/bravoseis_data/SADO/jan_2019/gravimetro_bruto.proc/21012019.gravimetro_bruto.proc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!head ~/Dropbox/QueensCollege/Research/BransfieldStrait/data/grav/raw/21012019.gravimetro_bruto.raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask import delayed\n",
    "import dask.array as dsa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Gravity Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_grav=dd.read_csv('/Users/dsoule/data/bravoseis_data/SADO/jan_2019/gravimetro_bruto.proc/*.proc', \n",
    "               parse_dates=['fecha'], date_parser=dateparse, \n",
    "                    dtype = {'fecha': object,'status': np.float64,\n",
    "                                'gravimetria_bruta': np.float64, 'spring_tension': np.float64,\n",
    "                                'longitud': np.float64, 'latitud': np.float64,\n",
    "                                'velocidad': np.float64,'rumbo': np.float64 })\n",
    "#df.partitions[5].compute()\n",
    "df_grav=df_grav.set_index(\"fecha\")\n",
    "del df_grav['fecha_telegrama']\n",
    "del df_grav['rumbo']\n",
    "del df_grav['velocidad']\n",
    "del df_grav['spring_tension']\n",
    "del df_grav['status']\n",
    "df_grav.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grav.index.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grav = df_grav.resample('s').mean().compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Bathy Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bath=dd.read_csv('/Users/dsoule/data/bravoseis_data/SADO/jan_2019/posicion.proc/*.proc', \n",
    "               parse_dates=['fecha'], date_parser=dateparse,\n",
    "               dtype = {'Date': object,'longitud': np.float64,\n",
    "                                'latitud': np.float64, 'rumbo': np.float64,\n",
    "                                'velocidad': np.float64, 'profundidad': np.float64,\n",
    "                                'cog': np.float64,'sog': np.float64 })\n",
    "#df.partitions[5].compute()\n",
    "df_bath=df_bath.set_index(\"fecha\")\n",
    "del df_bath['fecha_telegrama']\n",
    "del df_bath['rumbo']\n",
    "del df_bath['velocidad']\n",
    "df_bath.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bath.index.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bath = df_bath.resample('s').mean().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_bath.index = pd.to_datetime(df_bath.index.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.merge(df_bath, df_grav,how='inner', indicator=True,left_index=True, right_index=True, suffixes=('_B', '_G'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test = dd.merge(df_bath, df_grav,how='inner',right_index=True, left_index=True,suffixes=('_B', '_G')).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gravMerge = test[test['_merge'] == 'both']\n",
    "del df_gravMerge['_merge']\n",
    "df_gravMerge['longitud'] = df_gravMerge['longitud_G']\n",
    "df_gravMerge['latitud'] = df_gravMerge['latitud_G']\n",
    "del df_gravMerge['longitud_B']\n",
    "del df_gravMerge['latitud_B']\n",
    "del df_gravMerge['longitud_G']\n",
    "del df_gravMerge['latitud_G']\n",
    "df_gravMerge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_gravMerge.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downsample the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_minuteGrav = pd.DataFrame()\n",
    "df_minuteGrav['proc_gravity'] = df_gravMerge.gravimetria_bruta.resample('min').mean()\n",
    "#df_minuteGrav['eotvos'] = df_gravMerge.eotvos.resample('min').mean()\n",
    "#df_minuteGrav['grav_corr'] = df_gravMerge.gravimetria_bruta.resample('min').mean() + df_gravMerge.eotvos.resample('min').mean()\n",
    "df_minuteGrav['lon'] = df_gravMerge.longitud.resample('min').mean()\n",
    "df_minuteGrav['lat'] = df_gravMerge.latitud.resample('min').mean()\n",
    "df_minuteGrav['sog'] = df_gravMerge.sog.resample('min').mean()\n",
    "df_minuteGrav['cog'] = df_gravMerge.cog.resample('min').mean()\n",
    "df_minuteGrav['depth'] = df_gravMerge.profundidad.resample('min').mean()\n",
    "df_minuteGrav.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_minuteGrav.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_minuteGrav2=df_minuteGrav.loc['2019-01-20 00:00:00':'2019-01-24 00:00:00']\n",
    "df_temp=df_minuteGrav.loc['2019-01-26 21:00:00':'2019-02-05 23:58:00']\n",
    "df_minuteGrav2=df_minuteGrav2.append(df_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_minuteGrav2.hvplot.points('lon', 'lat', \n",
    "                      height=500, \n",
    "                      color='proc_gravity', \n",
    "                      cmap='colorwheel', \n",
    "                      size=3, \n",
    "                      hover_cols=['depth'], title= 'proc_gravity',\n",
    "                      fontsize={'title': 16, 'labels': 14, 'xticks': 12, 'yticks': 12})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_minuteGrav2.hvplot.heatmap(x='lon', y='lat', C='proc_gravity', reduce_function=np.mean, colorbar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Things to notice:\n",
    "1. The depth signiature is visable\n",
    "2. Examine crossing paths... there is a directioal dependence to our readings related to ship direction. \n",
    "3. Is the difference between these lines just the ETVOS correction or are their other corrections that need to be applied? \n",
    "4. Whould you please share the processing stream? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_minuteGrav2.hvplot.points('index', 'proc_gravity', color='proc_gravity',\n",
    "                             cmap='colorwheel', size=.5,\n",
    "                             hover_cols=['cog'], title= 'proc_gravity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_minuteGrav2.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond1 = df_minuteGrav2[\"lat\"] < -62.44    \n",
    "cond2 = df_minuteGrav2[\"lat\"] > -62.45\n",
    "cond3 = df_minuteGrav2[\"lon\"] > -58.42\n",
    "cond4 = df_minuteGrav2[\"lon\"] < -58.36\n",
    "\n",
    "df_minuteGrav3 = df_minuteGrav2[cond1 & cond2 & cond3 & cond4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_minuteGrav3['eotvos']\n",
    "del df_minuteGrav3['grav_corr']\n",
    "df_minuteGrav3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_minuteGrav3.hvplot.scatter('lon', 'lat', \n",
    "                      height=500, \n",
    "                      color='proc_gravity', \n",
    "                      cmap='colorwheel', \n",
    "                      size=50, \n",
    "                      hover_cols=['depth'], title= 'proc_gravity subset').opts(bgcolor= grey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_minuteGrav3.to_csv('proc_gravity_subset.csv') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The gravitational constant in SI units :math:`m^3 kg^{-1} s^{-1}`\n",
    "## GRAVITATIONAL_CONST = 0.00000000006673"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bouguer Correction\n",
    "#### The mass of the material between the gravity station and the datum also causes a variation of gravity with elevation (Figure 1). This mass effect causes gravity at higher stations to be greater than at stations with lower elevations and thus partly offsets the Free Air effect. To calculate the effect of this mass, a model of the topography must be constructed and its density must be estimated.\n",
    "\n",
    "#### The traditional approach is crude but has been proven to be effective. In this approach, each station is assumed to sit on a slab of material that extends to infinity laterally and to the elevation datum vertically (Figure 1). The formula for the gravitational attraction of this infinite slab is derived by employing a volume integral to calculate its mass. The resulting correction is named for the French geodesist Pierre Bouguer:\n",
    "\n",
    "## Bouguer Correction = BC = 2pgrh, where g is the International gravitational constant, r is the density, and h = (elevation - datum elevation).\n",
    "\n",
    "#### As discussed below, the need to estimate density for the calculation of the Bouguer correction is a significant source of uncertainty in gravity studies. With Gobs being observed gravity corrected for drift and tides, the Bouguer anomaly (BA) is then defined as:\n",
    "\n",
    "## BA = Gobs - Gt + FAC - BC\n",
    "\n",
    "#### If terrain corrections (see below) are not applied, the term simple Bouguer anomaly is used. If they have, the term complete Bouguer anomaly is used. A second order correction to account for the curvature of the Earth is often added to this calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ellipsoid = get_ellipsoid()\n",
    " #Convert latitude to radians\n",
    "    latitude_rad = np.radians(latitude)\n",
    "     prime_vertical_radius = ellipsoid.semimajor_axis / np.sqrt(1 - ellipsoid.first_eccentricity ** 2 * np.sin(latitude_rad) ** 2)\n",
    "        # Instead of computing X and Y, we only comupute the projection on the XY plane:\n",
    "        # xy_projection = sqrt( X**2 + Y**2 )\n",
    " xy_projection = (height + prime_vertical_radius) * np.cos(latitude_rad)\n",
    " z_cartesian = (height + (1 - ellipsoid.first_eccentricity ** 2) * prime_vertical_radius) * np.sin(latitude_rad)\n",
    " radius = np.sqrt(xy_projection ** 2 + z_cartesian ** 2)\n",
    " geocentric_latitude = 180 / np.pi * np.arcsin(z_cartesian / radius)\n",
    "\n",
    "    return geocentric_latitude, radius\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
